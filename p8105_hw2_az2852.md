p8105_hw2_az2852
================

``` r
library(tidyverse)
library(readxl)
```

# Problem 1

``` r
transit_df = 
  read_csv("./data/nyc_transit.csv", na = c("NA", ".", ""))%>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  distinct() %>% 
  mutate(across(c(route1: route11), as.character)) %>% 
  pivot_longer(
    cols = route1:route11,
    names_to = "route_count",
    names_prefix = "route",
    values_to = "subway_lines") %>% 
  drop_na("subway_lines") %>% 
  mutate(
    entry = case_match(
      entry,
      "YES"  ~ TRUE,
      "NO" ~ FALSE
    )) %>% 
  mutate(
    vending = case_match(
      vending,
      "YES"  ~ TRUE,
      "NO" ~ FALSE
    ))
```

The resulting dataset (1,566 × 10) contains information about each
entrance and exit for each subway station in NYC. Important variables
include line, station name, station latitude & longitude, routes served,
entry, entrance type, vending, and ADA compliance. So far, I’ve
converted all variable names to lower-case string format, removed
repeated rows, converted the original “route” variables to long format
under a new variable called “subway_lines”; the number of subway lines
running at each station is displayed under a variable called
“route_count”. I removed the NAs in the subway_lines column. Finally, I
converted the entry and vending variables to logical.

Now the data is tidy in the sense that you can clearly see which subway
lines are running at each station. There are no repeating rows and the
display is better. Converting the entry variable to logical allows us to
count the number of available entrances and see which stations have
available entrances.

According to the dataset:

- There are 465 distinct stations.
- 84 stations are ADA compliant.
- About 55% of stations without vending allow entrance.

The code for calculation are as follows:

``` r
transit_df %>% 
  distinct(line, station_name) %>% 
  nrow()
```

    ## [1] 465

``` r
transit_df %>% 
  distinct(line, station_name, .keep_all = TRUE) %>% 
  pull(ada) %>% 
  sum()
```

    ## [1] 84

``` r
no_vending_df = transit_df %>% 
  distinct(line, station_name, .keep_all = TRUE) %>% 
  filter(vending == FALSE)

no_vending_entry_df = no_vending_df %>% 
  filter(entry == TRUE)

nrow(no_vending_entry_df)/nrow(no_vending_df)
```

    ## [1] 0.5555556

## How many distinct stations serve the A train?

``` r
transit_df %>% 
  filter(subway_lines == "A") %>% 
  distinct(line, station_name, .keep_all = TRUE) %>% 
  nrow()
```

    ## [1] 60

60 distinct stations serve the A train.

## Of the stations that serve the A train, how many are ADA compliant?

``` r
transit_df %>% 
  filter(subway_lines == "A") %>% 
  distinct(line, station_name, .keep_all = TRUE) %>% 
  filter(ada == TRUE) %>% 
  nrow()
```

    ## [1] 17

Of the stations that serve the A train, 17 are ADA compliant.

# Problem 2

Read the Mr. Trashwheel dataset.

``` r
mr_trashwheel_df = 
    read_xlsx(
        path = "./data/trash_wheel.xlsx",
        sheet = "Mr. Trash Wheel",
        range = cell_cols("A:N")) %>% 
    janitor::clean_names() %>% 
    drop_na(dumpster) %>% 
    mutate(
        sports_balls = round(sports_balls),
        sports_balls = as.integer(sports_balls),
        year = as.numeric(year)
    ) 
```

Read Professor Trash Wheel dataset.

``` r
prof_trashwheel_df = 
    read_xlsx(
        path = "./data/trash_wheel.xlsx",
        sheet = "Professor Trash Wheel",
        range = cell_cols("A:M")) %>% 
    janitor::clean_names() %>% 
    drop_na(dumpster)
```

Read Gwynda Trash Wheel dataset.

``` r
gw_trashwheel_df = 
    read_xlsx(
        path = "./data/trash_wheel.xlsx",
        sheet = "Gwynnda Trash Wheel",
        range = cell_cols("A:L")) %>% 
    janitor::clean_names() %>% 
    drop_na(dumpster)
```

Now we try to combine the 3 datasets together. We observe that the 3
datasets have the same variables except that Prof Trashwheel lacks
“sports_balls” and Gwynnda Trashwheel lacks “glass_bottles” and
“sports_balls”. We need to add them before combining.

``` r
prof_trashwheel_tidy_df = 
  prof_trashwheel_df %>% 
  mutate(sports_balls = NA) %>% 
  select(1:which(names(prof_trashwheel_df) == "wrappers"), sports_balls, everything()) 
```

``` r
gw_trashwheel_tidy_df = 
  gw_trashwheel_df %>% 
  mutate(glass_bottles = NA, sports_balls = NA) %>% 
  select(1:which(names(gw_trashwheel_df) == "wrappers"), sports_balls, everything()) %>% 
  select(1:which(names(gw_trashwheel_df) == "cigarette_butts"), glass_bottles, everything())
```

Now combine the datasets.

``` r
all_trashwheels_df = bind_rows(mr_trashwheel_df, prof_trashwheel_tidy_df, gw_trashwheel_tidy_df)
```

This dataset (845 x 14) contains information from the Mr. Trashwheel
trash collectors in Baltimore, Maryland. As trash enters the inner
harbor, the trashwheels collect that trash, and store it in a dumpster.
The dataset contains information on year, month, and trash collected,
including specific kinds of trash. There are a total of 845 rows in our
final dataset.

- The total weight of trash collected by Professor Trash Wheel is 216.26
  tons.
- The total number of cigarette butts collected by Gwynnda in June of
  2022 is 18120.

``` r
sum(pull(prof_trashwheel_tidy_df, weight_tons))
```

    ## [1] 216.26

``` r
gw_trashwheel_tidy_df %>% 
  filter(year == 2022, month == "June") %>% 
  pull(cigarette_butts) %>% 
  sum()
```

    ## [1] 18120

# Problem 3

Import and clean the bakers dataset

``` r
bakers_df = 
  read_csv("./data/gbb/bakers.csv") %>% 
  janitor::clean_names() %>% 
  arrange(series) %>% 
  rename(baker = baker_name)
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Import and clean the bakes dataset

``` r
bakes_df = 
  read_csv("./data/gbb/bakes.csv", na = c("N/A", "UNKNOWN", "")) %>% 
  janitor::clean_names()
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Import and clean the results dataset.

``` r
results_df = 
  read_csv("./data/gbb/results.csv", skip = 2) %>% 
  janitor::clean_names()
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Now we want to create a big dataframe with all variables in one row:
series, episode, baker_name, baker_age, baker_occupation, hometown,
signature_bake, show_stopper, technical, result.

For the purpose of joining the datasets, I kept the first name of the
bakers. I joined the bakes dataset with the results dataset, using
variables “baker” “episode”, and “series” as the key and keeping the
observations in the results dataset. Then, I joined the dataset with the
baker dataset. The bakes dataset only contains information up to the 8th
season, so the bakes columns for the last 2 seasons are filled with NAs.

``` r
bakers_fn_df = bakers_df %>% 
  mutate(baker = word(baker, 1))
```

``` r
gbb_df =
  bakes_df %>% 
  right_join(results_df, by = c("baker", "episode", "series")) %>% 
  left_join(bakers_fn_df, by = c("baker", "series")) %>% 
  write_csv("./data/gbb/gbb.csv")
```

The dataset (1136x10) contains data from the 1st to 10th season of the
Great British Bakeoff. In each episode, contestants compete in signature
challenges, technical challenges, and a showstopper. At the end of an
episode the winner is crowned “Star Baker” (and winner in the last
episode of a season), and a loser is eliminated. The dataset contains
information about the contestants, their signature bakes and
showstoppers, and the results. Each row is information about one
contestant in one episode.

## Create a reader-friendly table showing the star baker or winner of each episode in Seasons 5 through 10. Comment on this table – were there any predictable overall winners? Any surprises?

``` r
winner5t10_df = 
  gbb_df %>% 
  filter(series %in% c(5,6,7,8,9,10)) %>% 
  filter(result %in% c("WINNER", "STAR BAKER")) %>% 
  select(-signature_bake, -show_stopper) %>% 
  write_csv("./data/gbb/winner5t10.csv")
```

If we are trying to predict the overall winner based on the star bakers
of each episode, we are out of luck. Surprisingly, the star baker in
most episodes tends not to be the overall winner of the season. The
winner tends to come from someone who is only the star baker in one or
two episodes. In the most extreme case, like in season 10, the winner is
someone who is never crowned star baker. In some seasons, the winner
tends to be the star baker of the last few episodes.

## Import, clean, tidy, and organize the viewership data in viewers.csv. Show the first 10 rows of this dataset. What was the average viewership in Season 1? In Season 5?

``` r
viewers_df =
  read_csv("./data/gbb/viewers.csv", na = "NA") %>% 
  janitor::clean_names()
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

- Mean viewership of season 1 is: 2.77
- Mean viewership of season 5 is: 10.0393

``` r
select(viewers_df, series_1) %>% 
  drop_na() %>% 
  pull() %>% 
  mean()
```

    ## [1] 2.77

``` r
select(viewers_df, series_5) %>% 
  drop_na() %>% 
  pull() %>% 
  mean()
```

    ## [1] 10.0393
